{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Sieci neuronowe - projekt 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Załadowanie bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Załadowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Vancouver</th>\n",
       "      <th>Portland</th>\n",
       "      <th>San Francisco</th>\n",
       "      <th>Seattle</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <th>San Diego</th>\n",
       "      <th>Las Vegas</th>\n",
       "      <th>Phoenix</th>\n",
       "      <th>Albuquerque</th>\n",
       "      <th>...</th>\n",
       "      <th>Philadelphia</th>\n",
       "      <th>New York</th>\n",
       "      <th>Montreal</th>\n",
       "      <th>Boston</th>\n",
       "      <th>Beersheba</th>\n",
       "      <th>Tel Aviv District</th>\n",
       "      <th>Eilat</th>\n",
       "      <th>Haifa</th>\n",
       "      <th>Nahariyya</th>\n",
       "      <th>Jerusalem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01 12:00:00</td>\n",
       "      <td>2.432746</td>\n",
       "      <td>2.050738</td>\n",
       "      <td>2.786702</td>\n",
       "      <td>2.118116</td>\n",
       "      <td>1.219548</td>\n",
       "      <td>1.751458</td>\n",
       "      <td>2.463482</td>\n",
       "      <td>1.909063</td>\n",
       "      <td>2.763685</td>\n",
       "      <td>...</td>\n",
       "      <td>2.643212</td>\n",
       "      <td>3.210954</td>\n",
       "      <td>3.831897</td>\n",
       "      <td>3.380889</td>\n",
       "      <td>1.989339</td>\n",
       "      <td>2.722306</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.299406</td>\n",
       "      <td>3.024292</td>\n",
       "      <td>1.880047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-01 14:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-01 15:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-01 16:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  Vancouver  Portland  San Francisco   Seattle  \\\n",
       "0  2012-10-01 12:00:00   2.432746  2.050738       2.786702  2.118116   \n",
       "1  2012-10-01 13:00:00   0.000000  0.000000       2.000000  0.000000   \n",
       "2  2012-10-01 14:00:00   0.000000  0.000000       2.000000  0.000000   \n",
       "3  2012-10-01 15:00:00   0.000000  0.000000       2.000000  0.000000   \n",
       "4  2012-10-01 16:00:00   0.000000  0.000000       2.000000  0.000000   \n",
       "\n",
       "   Los Angeles  San Diego  Las Vegas   Phoenix  Albuquerque  ...  \\\n",
       "0     1.219548   1.751458   2.463482  1.909063     2.763685  ...   \n",
       "1     0.000000   0.000000   0.000000  2.000000     4.000000  ...   \n",
       "2     0.000000   0.000000   0.000000  2.000000     4.000000  ...   \n",
       "3     0.000000   0.000000   0.000000  2.000000     4.000000  ...   \n",
       "4     0.000000   0.000000   0.000000  2.000000     4.000000  ...   \n",
       "\n",
       "   Philadelphia  New York  Montreal    Boston  Beersheba  Tel Aviv District  \\\n",
       "0      2.643212  3.210954  3.831897  3.380889   1.989339           2.722306   \n",
       "1      4.000000  7.000000  4.000000  3.000000   1.000000           0.000000   \n",
       "2      4.000000  7.000000  4.000000  3.000000   3.000000           0.000000   \n",
       "3      3.000000  7.000000  4.000000  3.000000   3.000000           0.000000   \n",
       "4      3.000000  7.000000  4.000000  3.000000   3.000000           0.000000   \n",
       "\n",
       "   Eilat     Haifa  Nahariyya  Jerusalem  \n",
       "0    8.0  3.299406   3.024292   1.880047  \n",
       "1    8.0  2.000000   2.000000   2.000000  \n",
       "2    8.0  2.000000   2.000000   2.000000  \n",
       "3    8.0  2.000000   2.000000   2.000000  \n",
       "4    8.0  2.000000   2.000000   2.000000  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_data = pd.read_csv('temperature.csv')\n",
    "wind_data = pd.read_csv('wind_speed.csv')\n",
    "\n",
    "#wind_data = wind_data.fillna(wind_data.drop(['datetime'], axis=1).mean())\n",
    "\n",
    "temperature_data = temperature_data.fillna(temperature_data.drop(['datetime'], axis=1).mean())\n",
    "wind_data = wind_data.fillna(wind_data.drop(['datetime'], axis=1).mean())\n",
    "\n",
    "temperature_data.head(5)\n",
    "wind_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Przetworzenie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_means_by_days(data):\n",
    "    data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "    data['date'] = data['datetime'].dt.date\n",
    "    data = data.drop('datetime', axis=1)\n",
    "    data = data.groupby('date').mean().reset_index()\n",
    "    data = data[['date'] + [col for col in data.columns if col != 'date']]\n",
    "\n",
    "    return data\n",
    "\n",
    "def check_max_wind_speed_by_days(data):\n",
    "    data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "    data['date'] = data['datetime'].dt.date\n",
    "    data = data.drop('datetime', axis=1)\n",
    "    data = data.groupby('date').max().reset_index()\n",
    "    data = data[['date'] + [col for col in data.columns if col != 'date']]\n",
    "\n",
    "    return data\n",
    "\n",
    "temperature_data = calculate_means_by_days(temperature_data)\n",
    "wind_data = check_max_wind_speed_by_days(wind_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Vancouver</th>\n",
       "      <th>Portland</th>\n",
       "      <th>San Francisco</th>\n",
       "      <th>Seattle</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <th>San Diego</th>\n",
       "      <th>Las Vegas</th>\n",
       "      <th>Phoenix</th>\n",
       "      <th>Albuquerque</th>\n",
       "      <th>...</th>\n",
       "      <th>Philadelphia</th>\n",
       "      <th>New York</th>\n",
       "      <th>Montreal</th>\n",
       "      <th>Boston</th>\n",
       "      <th>Beersheba</th>\n",
       "      <th>Tel Aviv District</th>\n",
       "      <th>Eilat</th>\n",
       "      <th>Haifa</th>\n",
       "      <th>Nahariyya</th>\n",
       "      <th>Jerusalem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>284.620769</td>\n",
       "      <td>282.118197</td>\n",
       "      <td>289.416642</td>\n",
       "      <td>281.767262</td>\n",
       "      <td>291.846501</td>\n",
       "      <td>291.573495</td>\n",
       "      <td>293.358911</td>\n",
       "      <td>296.701739</td>\n",
       "      <td>285.476208</td>\n",
       "      <td>...</td>\n",
       "      <td>286.043165</td>\n",
       "      <td>288.569420</td>\n",
       "      <td>285.887980</td>\n",
       "      <td>287.371091</td>\n",
       "      <td>306.621486</td>\n",
       "      <td>304.248983</td>\n",
       "      <td>310.158846</td>\n",
       "      <td>304.400000</td>\n",
       "      <td>304.400000</td>\n",
       "      <td>303.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>286.145190</td>\n",
       "      <td>286.137728</td>\n",
       "      <td>292.958306</td>\n",
       "      <td>285.156888</td>\n",
       "      <td>295.890450</td>\n",
       "      <td>295.291472</td>\n",
       "      <td>297.248385</td>\n",
       "      <td>301.211968</td>\n",
       "      <td>289.771821</td>\n",
       "      <td>...</td>\n",
       "      <td>289.239595</td>\n",
       "      <td>290.892389</td>\n",
       "      <td>286.937931</td>\n",
       "      <td>289.013090</td>\n",
       "      <td>302.226773</td>\n",
       "      <td>302.787467</td>\n",
       "      <td>306.759071</td>\n",
       "      <td>303.900000</td>\n",
       "      <td>303.900000</td>\n",
       "      <td>302.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-03</td>\n",
       "      <td>285.528125</td>\n",
       "      <td>289.599792</td>\n",
       "      <td>296.929167</td>\n",
       "      <td>287.673958</td>\n",
       "      <td>299.008542</td>\n",
       "      <td>297.878750</td>\n",
       "      <td>300.691875</td>\n",
       "      <td>302.867083</td>\n",
       "      <td>291.205417</td>\n",
       "      <td>...</td>\n",
       "      <td>290.353542</td>\n",
       "      <td>290.065625</td>\n",
       "      <td>287.374583</td>\n",
       "      <td>289.020833</td>\n",
       "      <td>301.194375</td>\n",
       "      <td>301.687917</td>\n",
       "      <td>303.289583</td>\n",
       "      <td>301.561042</td>\n",
       "      <td>301.502500</td>\n",
       "      <td>301.258125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-04</td>\n",
       "      <td>284.373333</td>\n",
       "      <td>286.482500</td>\n",
       "      <td>295.687083</td>\n",
       "      <td>284.391667</td>\n",
       "      <td>295.997917</td>\n",
       "      <td>296.080833</td>\n",
       "      <td>301.820000</td>\n",
       "      <td>302.232917</td>\n",
       "      <td>293.096250</td>\n",
       "      <td>...</td>\n",
       "      <td>293.633750</td>\n",
       "      <td>291.987083</td>\n",
       "      <td>286.860833</td>\n",
       "      <td>290.043750</td>\n",
       "      <td>300.094167</td>\n",
       "      <td>299.940000</td>\n",
       "      <td>301.770208</td>\n",
       "      <td>299.139167</td>\n",
       "      <td>299.139167</td>\n",
       "      <td>298.924167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>283.757292</td>\n",
       "      <td>288.286042</td>\n",
       "      <td>290.635417</td>\n",
       "      <td>284.756250</td>\n",
       "      <td>292.948333</td>\n",
       "      <td>293.894375</td>\n",
       "      <td>300.628542</td>\n",
       "      <td>301.811250</td>\n",
       "      <td>292.829167</td>\n",
       "      <td>...</td>\n",
       "      <td>294.015833</td>\n",
       "      <td>294.043542</td>\n",
       "      <td>287.535208</td>\n",
       "      <td>289.517292</td>\n",
       "      <td>299.712083</td>\n",
       "      <td>300.153125</td>\n",
       "      <td>299.860000</td>\n",
       "      <td>298.877500</td>\n",
       "      <td>298.877500</td>\n",
       "      <td>297.547500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   Vancouver    Portland  San Francisco     Seattle  Los Angeles  \\\n",
       "0  2012-10-01  284.620769  282.118197     289.416642  281.767262   291.846501   \n",
       "1  2012-10-02  286.145190  286.137728     292.958306  285.156888   295.890450   \n",
       "2  2012-10-03  285.528125  289.599792     296.929167  287.673958   299.008542   \n",
       "3  2012-10-04  284.373333  286.482500     295.687083  284.391667   295.997917   \n",
       "4  2012-10-05  283.757292  288.286042     290.635417  284.756250   292.948333   \n",
       "\n",
       "    San Diego   Las Vegas     Phoenix  Albuquerque  ...  Philadelphia  \\\n",
       "0  291.573495  293.358911  296.701739   285.476208  ...    286.043165   \n",
       "1  295.291472  297.248385  301.211968   289.771821  ...    289.239595   \n",
       "2  297.878750  300.691875  302.867083   291.205417  ...    290.353542   \n",
       "3  296.080833  301.820000  302.232917   293.096250  ...    293.633750   \n",
       "4  293.894375  300.628542  301.811250   292.829167  ...    294.015833   \n",
       "\n",
       "     New York    Montreal      Boston   Beersheba  Tel Aviv District  \\\n",
       "0  288.569420  285.887980  287.371091  306.621486         304.248983   \n",
       "1  290.892389  286.937931  289.013090  302.226773         302.787467   \n",
       "2  290.065625  287.374583  289.020833  301.194375         301.687917   \n",
       "3  291.987083  286.860833  290.043750  300.094167         299.940000   \n",
       "4  294.043542  287.535208  289.517292  299.712083         300.153125   \n",
       "\n",
       "        Eilat       Haifa   Nahariyya   Jerusalem  \n",
       "0  310.158846  304.400000  304.400000  303.500000  \n",
       "1  306.759071  303.900000  303.900000  302.675000  \n",
       "2  303.289583  301.561042  301.502500  301.258125  \n",
       "3  301.770208  299.139167  299.139167  298.924167  \n",
       "4  299.860000  298.877500  298.877500  297.547500  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Funkcje pomocnicze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawData(X, y, plot_name):\n",
    "    plt.style.use('dark_background')\n",
    "    plt.figure(figsize=(10,5))\n",
    "    axes = plt.gca()\n",
    "    axes.set(xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n",
    "    plt.title(plot_name, fontsize=30)\n",
    "    #plt.subplots_adjust(left=0.20)\n",
    "    #plt.subplots_adjust(right=0.80)\n",
    "\n",
    "    plt.scatter(X[0, :], X[1, :], c=y.ravel(), s=40, cmap=plt.cm.Spectral, edgecolors='black')\n",
    "\n",
    "def DrawDataCompare(X, y, y_pred):\n",
    "    plt.style.use('dark_background')\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    ax1.set(xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n",
    "    ax1.set_title('Actual labels', fontsize=20)\n",
    "    ax1.scatter(X[0, :], X[1, :], c=y.ravel(), s=40, cmap=plt.cm.Spectral, edgecolors='black')\n",
    "    \n",
    "    ax2.set(xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n",
    "    ax2.set_title('Predicted labels', fontsize=20)\n",
    "    ax2.scatter(X[0, :], X[1, :], c=y_pred.ravel(), s=40, cmap=plt.cm.Spectral, edgecolors='black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def GetClassificationData(name):\n",
    "    file = pd.read_csv(name, sep=\",\")\n",
    "\n",
    "    input = np.array(file[[\"x\", \"y\"]])\n",
    "    results = np.array(file[\"cls\"] - 1)\n",
    "\n",
    "    num_classes = results.max() + 1\n",
    "    \n",
    "    return input.T, results.T, num_classes\n",
    "\n",
    "def get_data_for_city(data, part):\n",
    "    n = len(data)\n",
    "    ind = int(n*part)\n",
    "    data_train = data[:ind].tolist()\n",
    "    data_test = data[ind+1:].tolist()\n",
    "    return data_train, data_test\n",
    "\n",
    "def get_windows(data):\n",
    "    n = len(data)\n",
    "    windows_X = []\n",
    "    windows_y = []\n",
    "\n",
    "    for i in range(n - 4):\n",
    "        window = data[i:i+3]\n",
    "        windows_X.append(window)\n",
    "        windows_y.append(data[i+4])\n",
    "\n",
    "    return windows_X, windows_y\n",
    "\n",
    "def convert_range(data, range_min, range_max):\n",
    "    old_min = data.min()\n",
    "    old_max = data.max()\n",
    "    return (((data - old_min) * (range_max - range_min)) / (old_max - old_min)) + range_min\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Funkcje aktywacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid():\n",
    "    @staticmethod\n",
    "    def calculate(x):\n",
    "        x = np.clip( x, -500, 500 )\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def calculateDeriv(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    \n",
    "class ReLU():\n",
    "    @staticmethod\n",
    "    def calculate(x):\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculateDeriv(x):\n",
    "        return x > 0\n",
    "    \n",
    "    \n",
    "class CrossEntropy():\n",
    "    @staticmethod\n",
    "    def calculate(y, y_pred):\n",
    "        y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "        return - (y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred)).mean()\n",
    "\n",
    "    @staticmethod\n",
    "    def calculateDeriv(y, y_pred):\n",
    "        y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "        return - (y / y_pred) + (1 - y) / (1 - y_pred)\n",
    "    \n",
    "class Softmax():\n",
    "    @staticmethod\n",
    "    def calculate(x):\n",
    "        x = np.clip(x, 1e-15, 1 - 1e-15)\n",
    "        e_x = np.exp(x - np.max(x, axis=0, keepdims=True))\n",
    "        return e_x / np.sum(e_x, axis=0, keepdims=True)\n",
    "    \n",
    "    def calculateDeriv(self, x):\n",
    "        value = self.calculate(x)\n",
    "        return value * (1 - value)\n",
    "    \n",
    "class MSE:\n",
    "    @staticmethod\n",
    "    def calculate(y, y_pred):\n",
    "        return ((y - y_pred) ** 2).mean()\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculateDeriv(y, y_pred):\n",
    "        return -2*(y - y_pred) / y.shape[0]\n",
    "    \n",
    "class MAE:\n",
    "    @staticmethod\n",
    "    def calculate(y, y_pred):\n",
    "        n = len(y)\n",
    "        return np.sum(np.abs(y- y_pred)) / n\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculateDeriv(y, y_pred):\n",
    "        n = len(y)\n",
    "        return np.sign(y_pred - y) / n\n",
    "        \n",
    "\n",
    "class Tanh:\n",
    "    @staticmethod\n",
    "    def calculate(x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculateDeriv(x):\n",
    "        return 1 - x ** 2\n",
    "    \n",
    "class Linear:\n",
    "    @staticmethod\n",
    "    def calculate(x):\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def calculateDeriv(x):\n",
    "        return np.ones_like(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Sieć neuronowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkStructure:\n",
    "    def __init__(self, inputSize, outputSize, hiddenLayerSizes, hiddenLayerFunction, outputLayerFunction):\n",
    "        self.inputSize = inputSize\n",
    "        self.outputSize = outputSize\n",
    "        self.hiddenLayerSizes = hiddenLayerSizes\n",
    "        self.layersSizes = hiddenLayerSizes + [outputSize]\n",
    "        self.activationFunction = [hiddenLayerFunction] * len(hiddenLayerSizes) + [outputLayerFunction]\n",
    "        self.layerInput = [None] * len(self.layersSizes)\n",
    "        self.layerOutput = [None] * len(self.layersSizes)\n",
    "\n",
    "        self.initializeWeights()\n",
    "\n",
    "    def initializeWeights(self):\n",
    "        self.weights = []\n",
    "        self.bias = []\n",
    "        \n",
    "        previousLayerSize = self.inputSize\n",
    "        for layerSize in self.layersSizes:\n",
    "            self.weights.append(np.random.rand(layerSize, previousLayerSize) - 0.5)\n",
    "            self.bias.append(np.random.rand(layerSize, 1) - 0.5)\n",
    "            previousLayerSize = layerSize\n",
    "            \n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, neuralNetworkStructure, epochs, learningRate, lossFunction, batchSize = 0):\n",
    "        self.structure = neuralNetworkStructure\n",
    "        self.lossFunction = lossFunction\n",
    "        self.learningRate = learningRate\n",
    "        self.epochs = epochs\n",
    "        self.batchSize = batchSize\n",
    "\n",
    "    def Forward(self, X):\n",
    "        previous_layer = X #np.reshape(X, (X.shape[0], 1))\n",
    "        for id in range(len(self.structure.layersSizes)):\n",
    "            self.structure.layerInput[id] = self.structure.weights[id].dot(previous_layer) + self.structure.bias[id]\n",
    "            self.structure.layerOutput[id] = self.structure.activationFunction[id].calculate(self.structure.layerInput[id])\n",
    "            previous_layer = self.structure.layerOutput[id]\n",
    "        return previous_layer\n",
    "    \n",
    "    \n",
    "    def Backward(self, X, ExpectedY, PredictedY):\n",
    "        if ExpectedY.ndim < 2:\n",
    "            ExpectedY = np.reshape(ExpectedY, (1, -1))\n",
    "        previous_layer_error = self.lossFunction.calculateDeriv(ExpectedY, PredictedY)\n",
    "        \n",
    "        for id in range(len(self.structure.layersSizes) -1, -1, -1):    \n",
    "            previous_layer_output = self.structure.layerOutput[id - 1] if id != 0 else X\n",
    "            \n",
    "            delta = previous_layer_error * self.structure.activationFunction[id].calculateDeriv(self.structure.layerOutput[id])\n",
    "            deltaW = np.dot(delta, previous_layer_output.T) \n",
    "            deltaB = np.sum(delta, axis=1, keepdims=True)\n",
    "            previous_layer_error = np.dot(self.structure.weights[id].T, delta)\n",
    "                                        \n",
    "            self.structure.weights[id] -= self.learningRate * deltaW / ExpectedY.shape[1]\n",
    "            self.structure.bias[id] -= self.learningRate * deltaB / ExpectedY.shape[1]\n",
    "    \n",
    "    def one_hot(self, Y):\n",
    "        one_hot_Y = np.zeros((Y.max() + 1, Y.size))\n",
    "        one_hot_Y[Y, np.arange(Y.size)] = 1\n",
    "        return one_hot_Y\n",
    "    \n",
    "    def Train(self, X, ExpectedY):\n",
    "   \n",
    "        predictedY = self.Forward(X)\n",
    "        self.Backward(X, ExpectedY, predictedY)\n",
    "    \n",
    "    def Test(self, train_inputs, train_results, test_inputs, schuffleParts = True):\n",
    "        train_inputs = np.array(train_inputs).T\n",
    "        train_results = np.array(train_results).T\n",
    "        test_inputs = np.array(test_inputs).T\n",
    "        \n",
    "        if self.batchSize != 0:\n",
    "            partsCount = (int)(np.shape(train_inputs)[1] / self.batchSize)\n",
    "        else:\n",
    "            partsCount = 1\n",
    "        \n",
    "        inputParts = np.array_split(train_inputs, partsCount, 1)\n",
    "        if train_results.ndim < 2:\n",
    "            resultsParts = np.array_split(train_results, partsCount, 0)\n",
    "        else:\n",
    "            resultsParts = np.array_split(train_results, partsCount, 1)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            parts_range = list(range(partsCount))\n",
    "            \n",
    "            if schuffleParts == True:\n",
    "                np.random.shuffle(parts_range)\n",
    "        \n",
    "            for i in parts_range:\n",
    "                self.Train(inputParts[i], resultsParts[i])\n",
    "            \n",
    "        return self.Forward(test_inputs) \n",
    "    \n",
    "    def Predict(self, test_inputs):\n",
    "        predictedY = self.Forward(test_inputs)\n",
    "        return predictedY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: Vancouver\n",
      "Correct predictions [error <= 2]: 786/1316, 59.72644376899696%\n",
      "Max error: 13.929207880483602\n",
      "Avg error: 1.9783872783833218\n",
      "City: Portland\n",
      "Correct predictions [error <= 2]: 615/1316, 46.73252279635258%\n",
      "Max error: 13.534938881385983\n",
      "Avg error: 2.670467560606342\n",
      "City: San Francisco\n",
      "Correct predictions [error <= 2]: 727/1316, 55.243161094224924%\n",
      "Max error: 11.658812799653617\n",
      "Avg error: 2.1760050457091995\n",
      "City: Seattle\n",
      "Correct predictions [error <= 2]: 696/1316, 52.88753799392097%\n",
      "Max error: 14.310711311415332\n",
      "Avg error: 2.311143692203107\n",
      "City: Los Angeles\n",
      "Correct predictions [error <= 2]: 802/1316, 60.94224924012158%\n",
      "Max error: 11.052762198917264\n",
      "Avg error: 1.957470415738773\n",
      "City: San Diego\n",
      "Correct predictions [error <= 2]: 757/1316, 57.52279635258358%\n",
      "Max error: 10.678584481526627\n",
      "Avg error: 2.0555830150457153\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[323], line 40\u001b[0m\n\u001b[0;32m     26\u001b[0m nnS \u001b[38;5;241m=\u001b[39m NeuralNetworkStructure(\n\u001b[0;32m     27\u001b[0m     inputSize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, \n\u001b[0;32m     28\u001b[0m     outputSize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \n\u001b[0;32m     29\u001b[0m     hiddenLayerSizes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m64\u001b[39m], \n\u001b[0;32m     30\u001b[0m     hiddenLayerFunction \u001b[38;5;241m=\u001b[39m Tanh(), \n\u001b[0;32m     31\u001b[0m     outputLayerFunction \u001b[38;5;241m=\u001b[39m Linear())\n\u001b[0;32m     33\u001b[0m nn \u001b[38;5;241m=\u001b[39m NeuralNetwork(  \n\u001b[0;32m     34\u001b[0m     epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3000\u001b[39m, \n\u001b[0;32m     35\u001b[0m     learningRate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m,\n\u001b[0;32m     36\u001b[0m     neuralNetworkStructure \u001b[38;5;241m=\u001b[39m nnS,\n\u001b[0;32m     37\u001b[0m     lossFunction \u001b[38;5;241m=\u001b[39m MAE(),\n\u001b[0;32m     38\u001b[0m     batchSize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m predictedPoints \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_windows_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_windows_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_windows_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m predictedPoints\n\u001b[0;32m     43\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_range(np\u001b[38;5;241m.\u001b[39marray(test_windows_y), prev_min, prev_max)\n",
      "Cell \u001b[1;32mIn[296], line 90\u001b[0m, in \u001b[0;36mNeuralNetwork.Test\u001b[1;34m(self, train_inputs, train_results, test_inputs, schuffleParts)\u001b[0m\n\u001b[0;32m     87\u001b[0m         np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(parts_range)\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m parts_range:\n\u001b[1;32m---> 90\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputParts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresultsParts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mForward(test_inputs)\n",
      "Cell \u001b[1;32mIn[296], line 64\u001b[0m, in \u001b[0;36mNeuralNetwork.Train\u001b[1;34m(self, X, ExpectedY)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mTrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, ExpectedY):\n\u001b[1;32m---> 64\u001b[0m     predictedY \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mForward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBackward(X, ExpectedY, predictedY)\n",
      "Cell \u001b[1;32mIn[296], line 36\u001b[0m, in \u001b[0;36mNeuralNetwork.Forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mlayersSizes)):\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mlayerInput[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mweights[\u001b[38;5;28mid\u001b[39m]\u001b[38;5;241m.\u001b[39mdot(previous_layer) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mbias[\u001b[38;5;28mid\u001b[39m]\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mlayerOutput[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivationFunction\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayerInput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     previous_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mlayerOutput[\u001b[38;5;28mid\u001b[39m]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m previous_layer\n",
      "Cell \u001b[1;32mIn[295], line 65\u001b[0m, in \u001b[0;36mTanh.calculate\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTanh\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate\u001b[39m(x):\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mtanh(x)\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculateDeriv\u001b[39m(x):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cities = temperature_data.columns\n",
    "cities = cities.drop(['date'])\n",
    "\n",
    "for city in cities:\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    prev_min = temperature_data[city].min()\n",
    "    prev_max = temperature_data[city].max()\n",
    "\n",
    "    temperature_data_converted = convert_range(temperature_data[city], 0, 1)\n",
    "\n",
    "    #windows_X, windows_y = get_windows(temperature_data_converted)\n",
    "\n",
    "    #from sklearn.model_selection import train_test_split\n",
    "    #train_windows_X, test_windows_X, train_windows_y, test_windows_y = train_test_split(windows_X, windows_y, test_size=0.7, random_state=0)\n",
    "\n",
    "    data_train, data_test = get_data_for_city(temperature_data_converted, 0.3)\n",
    "\n",
    "    train_windows_X, train_windows_y = get_windows(data_train)\n",
    "    test_windows_X, test_windows_y = get_windows(data_test)\n",
    "\n",
    "    nnS = NeuralNetworkStructure(\n",
    "        inputSize = 3, \n",
    "        outputSize = 1, \n",
    "        hiddenLayerSizes = [64], \n",
    "        hiddenLayerFunction = Tanh(), \n",
    "        outputLayerFunction = Linear())\n",
    "\n",
    "    nn = NeuralNetwork(  \n",
    "        epochs = 3000, \n",
    "        learningRate = 0.01,\n",
    "        neuralNetworkStructure = nnS,\n",
    "        lossFunction = MAE(),\n",
    "        batchSize=32)\n",
    "\n",
    "    predictedPoints = nn.Test(train_windows_X, train_windows_y, test_windows_X)\n",
    "    predictedPoints\n",
    "\n",
    "    converted = convert_range(np.array(test_windows_y), prev_min, prev_max)\n",
    "    predictedPoints = convert_range(np.array(predictedPoints), prev_min, prev_max)\n",
    "\n",
    "    diff = converted - predictedPoints[0]\n",
    "    err = abs(diff)\n",
    "\n",
    "    predictedPoints\n",
    "    print(f'City: {city}')\n",
    "    print(f'Correct predictions [error <= 2]: {np.sum(err <= 2)}/{len(err)}, {np.sum(np.sum(err <=2))/len(err)*100}%')\n",
    "    print(f'Max error: {np.max(err)}')\n",
    "    print(f'Avg error: {np.mean(err)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: Vancouver\n",
      "Correct predictions [error <= 2]: 288/1316, 21.88449848024316%\n",
      "Max error: 17.989957304115705\n",
      "Avg error: 5.846982298594307\n",
      "City: Portland\n",
      "Correct predictions [error <= 2]: 291/1316, 22.112462006079028%\n",
      "Max error: 19.314339554427193\n",
      "Avg error: 6.049399896335404\n",
      "City: San Francisco\n",
      "Correct predictions [error <= 2]: 483/1316, 36.702127659574465%\n",
      "Max error: 15.755855706365537\n",
      "Avg error: 3.474601201013479\n",
      "City: Seattle\n",
      "Correct predictions [error <= 2]: 293/1316, 22.264437689969604%\n",
      "Max error: 17.218885659196246\n",
      "Avg error: 5.6349457349923044\n",
      "City: Los Angeles\n",
      "Correct predictions [error <= 2]: 345/1316, 26.21580547112462%\n",
      "Max error: 15.840036284792632\n",
      "Avg error: 4.469552232648598\n",
      "City: San Diego\n",
      "Correct predictions [error <= 2]: 400/1316, 30.3951367781155%\n",
      "Max error: 16.101024799710103\n",
      "Avg error: 3.89567112505848\n",
      "City: Las Vegas\n",
      "Correct predictions [error <= 2]: 176/1316, 13.37386018237082%\n",
      "Max error: 23.375173581872332\n",
      "Avg error: 8.993039022463861\n",
      "City: Phoenix\n",
      "Correct predictions [error <= 2]: 222/1316, 16.869300911854104%\n",
      "Max error: 23.37664220146138\n",
      "Avg error: 7.8911597404268585\n",
      "City: Albuquerque\n",
      "Correct predictions [error <= 2]: 180/1316, 13.677811550151976%\n",
      "Max error: 25.73473060035957\n",
      "Avg error: 8.005069349000554\n",
      "City: Denver\n",
      "Correct predictions [error <= 2]: 175/1316, 13.297872340425531%\n",
      "Max error: 26.09815037611662\n",
      "Avg error: 8.801868651522668\n",
      "City: San Antonio\n",
      "Correct predictions [error <= 2]: 188/1316, 14.285714285714285%\n",
      "Max error: 19.430425084334615\n",
      "Avg error: 6.724307082229062\n",
      "City: Dallas\n",
      "Correct predictions [error <= 2]: 174/1316, 13.221884498480243%\n",
      "Max error: 21.456622015810694\n",
      "Avg error: 8.038313457961396\n",
      "City: Houston\n",
      "Correct predictions [error <= 2]: 207/1316, 15.729483282674773%\n",
      "Max error: 20.234722177000208\n",
      "Avg error: 6.287668358158789\n",
      "City: Kansas City\n",
      "Correct predictions [error <= 2]: 136/1316, 10.33434650455927%\n",
      "Max error: 26.31556993943701\n",
      "Avg error: 9.813267121295212\n",
      "City: Minneapolis\n",
      "Correct predictions [error <= 2]: 123/1316, 9.346504559270517%\n",
      "Max error: 26.588593063404232\n",
      "Avg error: 12.064788038401167\n",
      "City: Saint Louis\n",
      "Correct predictions [error <= 2]: 125/1316, 9.498480243161096%\n",
      "Max error: 24.738156597341288\n",
      "Avg error: 10.12763966830315\n",
      "City: Chicago\n",
      "Correct predictions [error <= 2]: 151/1316, 11.4741641337386%\n",
      "Max error: 26.2498307699789\n",
      "Avg error: 9.836535036107742\n",
      "City: Nashville\n",
      "Correct predictions [error <= 2]: 147/1316, 11.170212765957446%\n",
      "Max error: 24.269782400452527\n",
      "Avg error: 8.763242553585343\n",
      "City: Indianapolis\n",
      "Correct predictions [error <= 2]: 110/1316, 8.358662613981762%\n",
      "Max error: 26.569944816907793\n",
      "Avg error: 10.328054604620695\n",
      "City: Atlanta\n",
      "Correct predictions [error <= 2]: 162/1316, 12.310030395136778%\n",
      "Max error: 19.724487304038917\n",
      "Avg error: 7.93995590577773\n",
      "City: Detroit\n",
      "Correct predictions [error <= 2]: 136/1316, 10.33434650455927%\n",
      "Max error: 27.700950496488986\n",
      "Avg error: 10.269433814385074\n",
      "City: Jacksonville\n",
      "Correct predictions [error <= 2]: 226/1316, 17.17325227963526%\n",
      "Max error: 16.74868480789314\n",
      "Avg error: 5.629771008396359\n",
      "City: Charlotte\n",
      "Correct predictions [error <= 2]: 170/1316, 12.917933130699089%\n",
      "Max error: 23.594731468506893\n",
      "Avg error: 8.142761894253498\n",
      "City: Miami\n",
      "Correct predictions [error <= 2]: 501/1316, 38.06990881458967%\n",
      "Max error: 15.203110571143725\n",
      "Avg error: 2.9306540939230046\n",
      "City: Pittsburgh\n",
      "Correct predictions [error <= 2]: 127/1316, 9.650455927051672%\n",
      "Max error: 24.79472267566041\n",
      "Avg error: 9.719994485964808\n",
      "City: Toronto\n",
      "Correct predictions [error <= 2]: 153/1316, 11.626139817629179%\n",
      "Max error: 24.518575413638786\n",
      "Avg error: 9.693359992069674\n",
      "City: Philadelphia\n",
      "Correct predictions [error <= 2]: 133/1316, 10.106382978723403%\n",
      "Max error: 22.00286890946728\n",
      "Avg error: 9.5413731482699\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[314], line 35\u001b[0m\n\u001b[0;32m     21\u001b[0m nnS \u001b[38;5;241m=\u001b[39m NeuralNetworkStructure(\n\u001b[0;32m     22\u001b[0m     inputSize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, \n\u001b[0;32m     23\u001b[0m     outputSize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \n\u001b[0;32m     24\u001b[0m     hiddenLayerSizes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m64\u001b[39m], \n\u001b[0;32m     25\u001b[0m     hiddenLayerFunction \u001b[38;5;241m=\u001b[39m Tanh(), \n\u001b[0;32m     26\u001b[0m     outputLayerFunction \u001b[38;5;241m=\u001b[39m Linear())\n\u001b[0;32m     28\u001b[0m nn \u001b[38;5;241m=\u001b[39m NeuralNetwork(  \n\u001b[0;32m     29\u001b[0m     epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3000\u001b[39m, \n\u001b[0;32m     30\u001b[0m     learningRate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m,\n\u001b[0;32m     31\u001b[0m     neuralNetworkStructure \u001b[38;5;241m=\u001b[39m nnS,\n\u001b[0;32m     32\u001b[0m     lossFunction \u001b[38;5;241m=\u001b[39m MAE(),\n\u001b[0;32m     33\u001b[0m     batchSize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m predictedPoints \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_windows_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_windows_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_windows_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m predictedPoints\n\u001b[0;32m     38\u001b[0m diff \u001b[38;5;241m=\u001b[39m test_windows_y \u001b[38;5;241m-\u001b[39m predictedPoints[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[296], line 90\u001b[0m, in \u001b[0;36mNeuralNetwork.Test\u001b[1;34m(self, train_inputs, train_results, test_inputs, schuffleParts)\u001b[0m\n\u001b[0;32m     87\u001b[0m         np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(parts_range)\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m parts_range:\n\u001b[1;32m---> 90\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputParts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresultsParts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mForward(test_inputs)\n",
      "Cell \u001b[1;32mIn[296], line 64\u001b[0m, in \u001b[0;36mNeuralNetwork.Train\u001b[1;34m(self, X, ExpectedY)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mTrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, ExpectedY):\n\u001b[1;32m---> 64\u001b[0m     predictedY \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mForward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBackward(X, ExpectedY, predictedY)\n",
      "Cell \u001b[1;32mIn[296], line 36\u001b[0m, in \u001b[0;36mNeuralNetwork.Forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mlayersSizes)):\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mlayerInput[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mweights[\u001b[38;5;28mid\u001b[39m]\u001b[38;5;241m.\u001b[39mdot(previous_layer) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mbias[\u001b[38;5;28mid\u001b[39m]\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mlayerOutput[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivationFunction\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayerInput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     previous_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mlayerOutput[\u001b[38;5;28mid\u001b[39m]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m previous_layer\n",
      "Cell \u001b[1;32mIn[295], line 67\u001b[0m, in \u001b[0;36mTanh.calculate\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate\u001b[39m(x):\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtanh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cities = temperature_data.columns\n",
    "cities = cities.drop(['date'])\n",
    "\n",
    "for city in cities:\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    #windows_X, windows_y = get_windows(temperature_data[city])\n",
    "\n",
    "    #from sklearn.model_selection import train_test_split\n",
    "    #train_windows_X, test_windows_X, train_windows_y, test_windows_y = train_test_split(windows_X, windows_y, test_size=0.7, random_state=0)\n",
    "\n",
    "    data_train, data_test = get_data_for_city(temperature_data[city], 0.3)\n",
    "\n",
    "    train_windows_X, train_windows_y = get_windows(data_train)\n",
    "    test_windows_X, test_windows_y = get_windows(data_test)\n",
    "\n",
    "    nnS = NeuralNetworkStructure(\n",
    "        inputSize = 3, \n",
    "        outputSize = 1, \n",
    "        hiddenLayerSizes = [64], \n",
    "        hiddenLayerFunction = Tanh(), \n",
    "        outputLayerFunction = Linear())\n",
    "\n",
    "    nn = NeuralNetwork(  \n",
    "        epochs = 3000, \n",
    "        learningRate = 0.01,\n",
    "        neuralNetworkStructure = nnS,\n",
    "        lossFunction = MAE(),\n",
    "        batchSize=32)\n",
    "\n",
    "    predictedPoints = nn.Test(train_windows_X, train_windows_y, test_windows_X)\n",
    "    predictedPoints\n",
    "\n",
    "    diff = test_windows_y - predictedPoints[0]\n",
    "    err = abs(diff)\n",
    "\n",
    "    predictedPoints\n",
    "    print(f'City: {city}')\n",
    "    print(f'Correct predictions [error <= 2]: {np.sum(err <= 2)}/{len(err)}, {np.sum(np.sum(err <=2))/len(err)*100}%')\n",
    "    print(f'Max error: {np.max(err)}')\n",
    "    print(f'Avg error: {np.mean(err)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vancouver: <class '__main__.Sigmoid'> Correct predictions: 806/1319, 61.10689916603488%\n",
      "Vancouver: <class '__main__.Tanh'> Correct predictions: 813/1319, 61.63760424564063%\n",
      "Vancouver: <class '__main__.ReLU'> Correct predictions: 813/1319, 61.63760424564063%\n",
      "Portland: <class '__main__.Sigmoid'> Correct predictions: 942/1319, 71.4177407126611%\n",
      "Portland: <class '__main__.Tanh'> Correct predictions: 915/1319, 69.3707354056103%\n",
      "Portland: <class '__main__.ReLU'> Correct predictions: 942/1319, 71.4177407126611%\n",
      "San Francisco: <class '__main__.Sigmoid'> Correct predictions: 1015/1319, 76.95223654283548%\n",
      "San Francisco: <class '__main__.Tanh'> Correct predictions: 995/1319, 75.43593631539045%\n",
      "San Francisco: <class '__main__.ReLU'> Correct predictions: 1004/1319, 76.11827141774071%\n",
      "Seattle: <class '__main__.Sigmoid'> Correct predictions: 972/1319, 73.69219105382867%\n",
      "Seattle: <class '__main__.Tanh'> Correct predictions: 959/1319, 72.70659590598939%\n",
      "Seattle: <class '__main__.ReLU'> Correct predictions: 972/1319, 73.69219105382867%\n",
      "Los Angeles: <class '__main__.Sigmoid'> Correct predictions: 1053/1319, 79.83320697498104%\n",
      "Los Angeles: <class '__main__.Tanh'> Correct predictions: 1053/1319, 79.83320697498104%\n",
      "Los Angeles: <class '__main__.ReLU'> Correct predictions: 1077/1319, 81.6527672479151%\n",
      "San Diego: <class '__main__.Sigmoid'> Correct predictions: 1044/1319, 79.15087187263077%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[327], line 48\u001b[0m\n\u001b[0;32m     34\u001b[0m nnS \u001b[38;5;241m=\u001b[39m NeuralNetworkStructure(\n\u001b[0;32m     35\u001b[0m     inputSize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, \n\u001b[0;32m     36\u001b[0m     outputSize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \n\u001b[0;32m     37\u001b[0m     hiddenLayerSizes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m64\u001b[39m], \n\u001b[0;32m     38\u001b[0m     hiddenLayerFunction \u001b[38;5;241m=\u001b[39m function, \n\u001b[0;32m     39\u001b[0m     outputLayerFunction \u001b[38;5;241m=\u001b[39m Softmax())\n\u001b[0;32m     41\u001b[0m nn \u001b[38;5;241m=\u001b[39m NeuralNetwork(  \n\u001b[0;32m     42\u001b[0m     epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m, \n\u001b[0;32m     43\u001b[0m     learningRate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m,\n\u001b[0;32m     44\u001b[0m     neuralNetworkStructure \u001b[38;5;241m=\u001b[39m nnS,\n\u001b[0;32m     45\u001b[0m     lossFunction \u001b[38;5;241m=\u001b[39m CrossEntropy(),\n\u001b[0;32m     46\u001b[0m     batchSize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m predictedPoints \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_windows_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_windows_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_windows_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m diff \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictedPoints, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m test_windows_y\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(function)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Correct predictions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39msum(diff)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(diff)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39msum(diff)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(diff)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[296], line 90\u001b[0m, in \u001b[0;36mNeuralNetwork.Test\u001b[1;34m(self, train_inputs, train_results, test_inputs, schuffleParts)\u001b[0m\n\u001b[0;32m     87\u001b[0m         np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(parts_range)\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m parts_range:\n\u001b[1;32m---> 90\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputParts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresultsParts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mForward(test_inputs)\n",
      "Cell \u001b[1;32mIn[296], line 65\u001b[0m, in \u001b[0;36mNeuralNetwork.Train\u001b[1;34m(self, X, ExpectedY)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mTrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, ExpectedY):\n\u001b[0;32m     64\u001b[0m     predictedY \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mForward(X)\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mExpectedY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictedY\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[296], line 50\u001b[0m, in \u001b[0;36mNeuralNetwork.Backward\u001b[1;34m(self, X, ExpectedY, PredictedY)\u001b[0m\n\u001b[0;32m     47\u001b[0m previous_layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mlayerOutput[\u001b[38;5;28mid\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m     49\u001b[0m delta \u001b[38;5;241m=\u001b[39m previous_layer_error \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mactivationFunction[\u001b[38;5;28mid\u001b[39m]\u001b[38;5;241m.\u001b[39mcalculateDeriv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mlayerOutput[\u001b[38;5;28mid\u001b[39m])\n\u001b[1;32m---> 50\u001b[0m deltaW \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_layer_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     51\u001b[0m deltaB \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(delta, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     52\u001b[0m previous_layer_error \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mweights[\u001b[38;5;28mid\u001b[39m]\u001b[38;5;241m.\u001b[39mT, delta)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def convert(x):\n",
    "  return 1 if x >= 6 else 0\n",
    "\n",
    "cities = wind_data.columns\n",
    "cities = cities.drop(['date'])\n",
    "\n",
    "for city in cities:\n",
    "    \n",
    "    np.random.seed(0)\n",
    "\n",
    "    wind_data_class = np.apply_along_axis(np.vectorize(convert), -1, wind_data[city])\n",
    "\n",
    "    windows_X, windows_y = get_windows(wind_data_class)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_windows_X, test_windows_X, train_windows_y, test_windows_y = train_test_split(windows_X, windows_y, test_size=0.7, random_state=0)\n",
    "\n",
    "    def one_hot(Y):\n",
    "        one_hot_Y = np.zeros((Y.max() + 1, Y.size))\n",
    "        one_hot_Y[Y, np.arange(Y.size)] = 1\n",
    "        return one_hot_Y\n",
    "\n",
    "    train_windows_y = one_hot(np.array(train_windows_y).astype(int)).T\n",
    "    train_windows_y\n",
    "\n",
    "    functions = [Sigmoid(), Tanh(), ReLU()]\n",
    "    \n",
    "    for function in functions:\n",
    "        \n",
    "        nnS = NeuralNetworkStructure(\n",
    "            inputSize = 3, \n",
    "            outputSize = 2, \n",
    "            hiddenLayerSizes = [64], \n",
    "            hiddenLayerFunction = function, \n",
    "            outputLayerFunction = Softmax())\n",
    "\n",
    "        nn = NeuralNetwork(  \n",
    "            epochs = 1000, \n",
    "            learningRate = 0.01,\n",
    "            neuralNetworkStructure = nnS,\n",
    "            lossFunction = CrossEntropy(),\n",
    "            batchSize=32)\n",
    "\n",
    "        predictedPoints = nn.Test(train_windows_X, train_windows_y, test_windows_X)\n",
    "        diff = np.argmax(predictedPoints, 0) == test_windows_y\n",
    "        print(f'{city}: {type(function)} Correct predictions: {np.sum(diff)}/{len(diff)}, {np.sum(diff)/len(diff)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vancouver Correct predictions: 662/1319, 50.18953752843063%\n",
      "Portland Correct predictions: 686/1319, 52.00909780136467%\n",
      "San Francisco Correct predictions: 1082/1319, 82.03184230477635%\n",
      "Seattle Correct predictions: 485/1319, 36.770280515542076%\n",
      "Los Angeles Correct predictions: 809/1319, 61.33434420015163%\n",
      "San Diego Correct predictions: 1064/1319, 80.66717210007582%\n",
      "Las Vegas Correct predictions: 848/1319, 64.29112964366944%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[315], line 35\u001b[0m\n\u001b[0;32m     21\u001b[0m nnS \u001b[38;5;241m=\u001b[39m NeuralNetworkStructure(\n\u001b[0;32m     22\u001b[0m     inputSize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, \n\u001b[0;32m     23\u001b[0m     outputSize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \n\u001b[0;32m     24\u001b[0m     hiddenLayerSizes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m64\u001b[39m], \n\u001b[0;32m     25\u001b[0m     hiddenLayerFunction \u001b[38;5;241m=\u001b[39m Tanh(), \n\u001b[0;32m     26\u001b[0m     outputLayerFunction \u001b[38;5;241m=\u001b[39m Linear())\n\u001b[0;32m     28\u001b[0m nn \u001b[38;5;241m=\u001b[39m NeuralNetwork(  \n\u001b[0;32m     29\u001b[0m     epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3000\u001b[39m, \n\u001b[0;32m     30\u001b[0m     learningRate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m,\n\u001b[0;32m     31\u001b[0m     neuralNetworkStructure \u001b[38;5;241m=\u001b[39m nnS,\n\u001b[0;32m     32\u001b[0m     lossFunction \u001b[38;5;241m=\u001b[39m MAE(),\n\u001b[0;32m     33\u001b[0m     batchSize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m predictedPoints \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_windows_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_windows_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_windows_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m predictedPoints\n\u001b[0;32m     38\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_range(np\u001b[38;5;241m.\u001b[39marray(test_windows_y), prev_min, prev_max)\n",
      "Cell \u001b[1;32mIn[296], line 90\u001b[0m, in \u001b[0;36mNeuralNetwork.Test\u001b[1;34m(self, train_inputs, train_results, test_inputs, schuffleParts)\u001b[0m\n\u001b[0;32m     87\u001b[0m         np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(parts_range)\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m parts_range:\n\u001b[1;32m---> 90\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputParts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresultsParts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mForward(test_inputs)\n",
      "Cell \u001b[1;32mIn[296], line 64\u001b[0m, in \u001b[0;36mNeuralNetwork.Train\u001b[1;34m(self, X, ExpectedY)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mTrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, ExpectedY):\n\u001b[1;32m---> 64\u001b[0m     predictedY \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mForward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBackward(X, ExpectedY, predictedY)\n",
      "Cell \u001b[1;32mIn[296], line 36\u001b[0m, in \u001b[0;36mNeuralNetwork.Forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mlayersSizes)):\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mlayerInput[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mweights[\u001b[38;5;28mid\u001b[39m]\u001b[38;5;241m.\u001b[39mdot(previous_layer) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mbias[\u001b[38;5;28mid\u001b[39m]\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mlayerOutput[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivationFunction\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayerInput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     previous_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure\u001b[38;5;241m.\u001b[39mlayerOutput[\u001b[38;5;28mid\u001b[39m]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m previous_layer\n",
      "Cell \u001b[1;32mIn[295], line 67\u001b[0m, in \u001b[0;36mTanh.calculate\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate\u001b[39m(x):\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtanh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cities = wind_data.columns\n",
    "cities = cities.drop(['date'])\n",
    "\n",
    "for city in cities:\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    prev_min = wind_data[city].min()\n",
    "    prev_max = wind_data[city].max()\n",
    "\n",
    "    wind_data_regression = convert_range(wind_data[city], 0, 1)\n",
    "\n",
    "    windows_X, windows_y = get_windows(wind_data_regression)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_windows_X, test_windows_X, train_windows_y, test_windows_y = train_test_split(windows_X, windows_y, test_size=0.7, random_state=0)\n",
    "\n",
    "    nnS = NeuralNetworkStructure(\n",
    "        inputSize = 3, \n",
    "        outputSize = 1, \n",
    "        hiddenLayerSizes = [64], \n",
    "        hiddenLayerFunction = Tanh(), \n",
    "        outputLayerFunction = Linear())\n",
    "\n",
    "    nn = NeuralNetwork(  \n",
    "        epochs = 3000, \n",
    "        learningRate = 0.01,\n",
    "        neuralNetworkStructure = nnS,\n",
    "        lossFunction = MAE(),\n",
    "        batchSize=32)\n",
    "\n",
    "    predictedPoints = nn.Test(train_windows_X, train_windows_y, test_windows_X)\n",
    "    predictedPoints\n",
    "\n",
    "    converted = convert_range(np.array(test_windows_y), prev_min, prev_max)\n",
    "    predictedPoints = convert_range(np.array(predictedPoints), prev_min, prev_max)\n",
    "\n",
    "    diff = (converted >= 6) == (predictedPoints[0] >= 6) \n",
    "\n",
    "    print(f'{city} Correct predictions: {np.sum(diff)}/{len(diff)}, {np.sum(diff)/len(diff)*100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
